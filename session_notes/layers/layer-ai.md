# Layer AI: AI 协作专属层 — 详细定义

> 本文件是 [INDEX.md](../INDEX.md) 的展开。AI 按需读取，不在 startup 时加载。
> 这些原则专用于人类与 AI 协作的场景。传统软件工程里没有对应概念。

---

### AI-01: Context Window Management — 上下文窗口管理

**含义**: AI 的"工作台"有大小限制。对话内容、文件读取、工具输出都会消耗空间。满了之后 AI 会"忘记"旧内容。

**类比**: 上下文窗口 = 书桌大小。资料堆满了书桌，新资料摆在旧资料上面，下面的就看不见了。

**大量消耗上下文的行为**: 读大文件、反复改文件、长对话

**AI 能主动报告吗？**: AI 看不到自己的 token 计数，但可以规则估算预警（`role-SECA.md` Section 6）。

**信号识别**: AI 忘记前面说过的事 / 回复变短 / 系统出现 checkpoint / truncated

**解决方案**: 大任务拆成多个对话 + `last_session.md` 断点续传

**注意力边缘效应** (来源: 社区经验分享, ~2026-01, 可能过时):
- 上下文快满时，AI 不是均匀遗忘，而是**注意力乱飘**
- 单文件/prompt ≤ 400 行是 AI 有效注意力的实际上限 `[个人经验, 未独立验证]`
- 单次喂给 AI 的文件 token 最好为最大限制的 **40-60%** `[同上]`

**出现记录**: [2026-02-11-late-2 规则10](../projects/001-textbook/2026-02-11-late-2.md), [2026-02-11-late-3 规则13](../projects/001-textbook/2026-02-11-late-3.md)

---

### AI-02: Selective Memory — 选择性记忆

**含义**: AI 跨对话默认遗忘一切。"记住"靠 `_ai_evolution/` 文件，"遗忘"靠删除对应文件。

**机制**: 想让 AI 记住 → 写入文件。想让 AI 遗忘 → 删除文件。AI 无法在对话内选择性遗忘。

**Memory 的 200 行真相** (来源: 社区经验分享, ~2026-01, 可能随版本更新):
- Claude Code 内置 memory 仅限 200 行 `[个人经验, 未查官方文档]`
- 大量 markdown 堆砌的"结构化 memory"多数是假象
- 有效做法：**分层索引 + 按需加载**（质量 > 数量）

**出现记录**: [2026-02-11-late-3 规则15](../projects/001-textbook/2026-02-11-late-3.md)

---

### AI-03: AI Generation Pitfall Awareness — AI 生成通病预防

**含义**: AI 生成内容有系统性倾向，不是偶尔出错，而是几乎每次都会这样。

**四大通病**:

| 通病 | AI 的倾向 | 预防 |
|------|----------|------|
| **堆砌** | 全塞进一个文件/函数 | 设大小阈值 (`PRACTICE-05`) |
| **冗余** | 生成重复/未使用的代码 | 完成后审查"是否被引用" |
| **作用域混乱** | 过度使用全局变量 | 要求解释变量生命周期 |
| **测试绕过** | 改测试来绕过 Bug `[社区经验]` | 关键测试预期由人类定义 |

**已写入 `role-SECA.md`**: Section 3 POST-GENERATION SELF-CHECK。

**出现记录**: 2026-02-11 Vibe-Poo 分析, [2026-02-11-late-3 规则14/18](../projects/001-textbook/2026-02-11-late-3.md)

---

### AI-04: AI Personality Bias — AI 性格偏差

**含义**: 不同 AI 模型有系统性"性格缺陷"。Claude 保守、ChatGPT 创造性胡说、Gemini 吹捧。

**对冲方法**: 要求 AI 给出具体理由而非笼统评价。

**出现记录**: [2026-02-11-late-3 规则12](../projects/001-textbook/2026-02-11-late-3.md)

---

### AI-05: Hard Constraint Derailment — 硬约束导致计划脱轨

**含义**: 触发型硬约束可能打断 AI 正在并行执行的多个任务。修复后 AI 可能忘记之前的计划。

**对策**: 硬约束越少越好 (KISS)。优先用"事后检查"替代"中断式触发"。

**出现记录**: [2026-02-11-late-3 规则16](../projects/001-textbook/2026-02-11-late-3.md)

---

### AI-06: Knowledge Expiry — AI 知识有保质期

**含义**: AI 知识有截止日期。涉及版本敏感的决策时，AI 可能用过时知识判断且不主动声明。

**对策**: 版本敏感决策要求 AI 搜索最新文档。

**已写入 `role-SECA.md`**: Section 8 KNOWLEDGE EXPIRY AWARENESS。

**出现记录**: [2026-02-11-late-3 规则17](../projects/001-textbook/2026-02-11-late-3.md)

---

### AI-07: Token Economy — Token 是 AI 工程的核心资源

**含义**: Token 同时是钱和 AI 注意力。省 Token = 省钱 + AI 回答质量更高。

**六种优化策略**: Lazy Loading、指针/引用、Checkpoint、最小启动集、确定性优先、规则精简。

**关键认知**: 减少对话轮次比缩短每轮更有效。一次做准比试三次更省。

**出现记录**: [2026-02-11-late-4 规则22](../projects/001-textbook/2026-02-11-late-4.md)

---

### AI-08: Spark Capture — 跨任务直觉捕获

**含义**: AI 在讨论任务 A 时产生的关于任务 B 的直觉，不能"记在脑子里"（AI 没有脑子）。必须立即写入对应项目的 `sparks.md`，等做任务 B 时主动唤醒。

**与已有概念的区别**:

| 已有概念 | Spark 的区别 |
|---------|------------|
| GTD Inbox | GTD 是人的待办，Spark 是 AI 跨 session 的直觉传递 |
| Fleeting Notes | 闪念笔记没有唤醒机制和生命周期管理 |
| Backlog | Backlog 是已确认的任务，Spark 是未验证的直觉 |

**生命周期**: 捕获 → 休眠 → 唤醒 → 验证 → 实现/淘汰

**文件位置**: `session_notes/projects/{项目代号}/sparks.md`

**唤醒机制**: 开始某项目任务时，扫一眼该项目的 `sparks.md`。

**出现记录**: 2026-02-12 讨论中发现"记在脑子里"对 AI 无效

---

### AI-09: Human Cognitive Budget — 人类认知预算

**含义**: AI 提升产出速度后，任务数量倾向于等比膨胀。但人类的决策力、注意力、审阅能力是有限资源，不会因为 AI 变快而增加。需要主动施加限速机制。

**AI-07 的对称概念**: AI-07 管 AI 的 token 预算，AI-09 管人类的认知预算。

**核心矛盾**: AI 降低生产成本，但增加协调、审阅和决策成本。后者完全由人类承担。

**实施策略**:

| 策略 | 做法 | 原理 |
|------|------|------|
| Time-boxing | 30分钟计时器，到时间 ship 或手写 | Backpressure |
| 分离时段 | 早上纯思考，下午 AI 辅助执行 | ARCH-01 (SoC) |
| 接受 70% | AI 输出 70% 可用即可，其余手动修 | Good Enough |
| 审阅分层 | 安全/数据/错误路径重点审，其余靠自动化 | PRACTICE-04 |
| 使用日志 | 记录用AI/不用AI/耗时/满意度 | DESIGN-02 (Data) |

**审阅疲劳补充** (扩展 AI-03):
- 审阅 AI 代码比自己写代码更消耗认知资源
- 创造型工作→心流状态；审阅型工作→决策疲劳
- 一天超过 60% 时间在审阅 AI 输出 → 高 burnout 风险

**三次原则 / Stop-Loss** (扩展 AI-07):
- 3 次 prompt 未达 70% 可用 → 立即手写，不例外
- 防止 Prompt Spiral (递减收益陷阱)

**出现记录**: [2026-02-13-am-1 规则32/33/36/38](../projects/001-textbook/2026-02-13-am-1.md)

---

### AI-10: Thinking Independence — 独立思维能力

**含义**: 长期把 "first-draft thinking" 外包给 AI，从零推理的能力会退化。类比：GPS 用久了导航能力退化。

**为什么重要**: 独立推理能力是审阅 AI 输出质量的前提。思维萎缩→审阅能力下降→更依赖 AI→进一步萎缩。恶性循环。

**与 SOAR (规则25) 的关系**: SOAR 说学习需要挣扎。Thinking Independence 说维持能力也需要挣扎。

**对策**: 每天保留一段无 AI 思考时间（手画架构、纸上推理）。感觉低效，但能维持思维锐度。

**非确定性心理成本** (扩展 PRACTICE-07):
- AI 是概率系统，工程师大脑为确定性优化
- 这种 mismatch 产生持续的低级背景焦虑
- 对策：把 AI 当"聪明但不稳定的实习生"，预期重写 30%

**出现记录**: [2026-02-13-am-1 规则34/37](../projects/001-textbook/2026-02-13-am-1.md)
