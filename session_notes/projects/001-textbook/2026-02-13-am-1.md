# 2026-02-13 凌晨 会话笔记 1

> **来源**: "AI fatigue is real and nobody talks about it" — Siddhant Khare
> **作者背景**: OpenFGA (CNCF Incubating) 核心维护者，agent infrastructure 开发者，构建了 agentic-authz, Distill, MCP servers
> **证据强度**: [个人深度经验] — 作者是全职 agent infra 工程师，非旁观者。多数观点有具体场景支撑，但缺乏统计数据。
> **发表时间**: ~2026 年中（推测），知识有效期 ≥ 1 年（讨论的是人类认知层面问题，不依赖具体工具版本）

---

## 文章核心论点

AI 让单个任务确实加速了（3h → 45min），但工程师整体更累了。原因不在于工具不好用，而在于 **AI 消除了人类产出的天然速度限制**。生产速度提升 → 期望提升 → 工作量增加 → 认知耗竭。作者在 2025 年末 burnout，之后总结出的恢复策略。

---

## 规则提取

## 规则 32: Production Cost Paradox — 生产力悖论

> AI 降低生产成本，但增加协调、审阅和决策成本。后者完全由人类承担。

**原文证据**:
- "When each task takes less time, you don't do fewer tasks. You do more tasks."
- "I might touch six different problems in a day. Each one 'only takes an hour with AI.' But context-switching between six problems is brutally expensive for the human brain."

**可迁移规则**: AI 提速后，不要让任务数量等比膨胀。**日任务上限应由人类认知带宽决定，而非AI产出速度。**

**INDEX 映射**: 新概念 → 建议创建 **AI-09: Human Cognitive Budget**

**与已有原则关系**: AI-07 (Token Economy) 管的是 AI 的 token 预算，AI-09 管的是人类的认知预算。对称概念。

---

## 规则 33: Review Fatigue — 审阅疲劳

> AI 把工程师从"创造者"变成"审阅者"。创造型工作产生心流，审阅型工作产生决策疲劳。

**原文证据**:
- "Creating is energizing. Reviewing is draining. Generative work gives you flow states. Evaluative work gives you decision fatigue."
- "AI-generated code requires more careful review than human-written code. [...] With AI, every line is suspect."

**可迁移规则**: 如果一天中超过 60% 的时间在审阅 AI 输出而非自己创造，认知耗竭风险极高。需要主动安排"创造型"工作时间来平衡。

**INDEX 映射**: 扩展 **AI-03** (Generation Pitfalls) — 增加"审阅成本"维度

**实践建议**: 不要 review 所有 AI 输出。集中精力在 security boundaries、data handling、error paths。其余靠 automated tests + static analysis。

---

## 规则 34: Nondeterminism Tax — 非确定性税

> AI 是概率系统，工程师的大脑为确定性系统优化。这种 mismatch 是持续的低级焦虑来源。

**原文证据**:
- "I had a prompt that worked perfectly on Monday. [...] I used the same prompt on Tuesday for a similar endpoint. The output was structurally different."
- "There's no stack trace for 'the model decided to go a different direction today.'"
- "You are collaborating with a probabilistic system, and your brain is wired for deterministic ones."

**可迁移规则**: 接受 AI 输出的非确定性。**把 AI 当作"聪明但不稳定的实习生"——期望重写 30%，预算好这个时间。**

**INDEX 映射**: 扩展 **PRACTICE-07** (Deterministic-First) — AI 在 pipeline 中越靠后、输出越不可控。尽量让确定性组件处理输入/验证，AI 只做草稿。

**与已有原则关系**: 作者的应对方式（构建 Distill 做确定性上下文去重）完全符合 PRACTICE-07 的精神：能用确定性方案的部分，就不用概率方案。

---

## 规则 35: FOMO Treadmill — FOMO 跑步机 (工具追逐陷阱)

> 每周新框架、新工具。追逐 frontier 的成本远超收益。知识快速衰减。

**原文证据**:
- "I'd spend Saturday afternoon setting up a new AI coding tool. By Sunday I'd have a basic workflow. By the following Wednesday, someone would post about a different tool that was 'way better.'"
- "I spent two weeks building a sophisticated prompt engineering workflow [...] Three months later, the model updated [...] and half my templates produced worse results."
- "The people who waited and did nothing often ended up in a better position than the people who adopted early and had to migrate twice."

**可迁移规则**: **投资不会 churn 的基础层**，而非追逐 trending 的工具层。Context efficiency, authorization, audit trails — 这些是耐久问题。

**INDEX 映射**: 扩展 **PRACTICE-02** (Dependency Weight) — 工具依赖也有"重量"，migration cost = (学习成本 + 集成编写 + 知识衰减风险)

**对我们的启示**: `_ai_evolution/` 的设计本身就是 anti-churn: 不绑定任何特定 AI 工具，只依赖 markdown 文件。正确。

---

## 规则 36: Prompt Spiral — Prompt 螺旋 (递减收益陷阱)

> 反复 re-prompt 试图获得完美输出，每轮微小改善但成本递增。45 分钟后发现手写只要 20 分钟。

**原文证据**:
- "30 minutes later you're debugging your prompt instead of debugging your code."
- "The marginal returns are diminishing fast."

**可迁移规则**: **三次原则** — 如果三次 prompt 仍未达到 70% 可用，立即手写，不例外。

**INDEX 映射**: 新战术规则。可并入 **AI-07** (Token Economy) 作为 "Stop-Loss" 策略补充。

**与已有原则关系**: AI-07 说"减轮次比缩每轮更有效"，规则 36 给出了具体阈值：3 轮。

---

## 规则 37: Thinking Atrophy — 思维萎缩

> 长期把"first-draft thinking"外包给 AI，从零推理的能力会退化。类比 GPS 与导航能力。

**原文证据**:
- "Someone asked me to reason through a concurrency problem on the whiteboard. No laptop. No AI. Just me and a marker. And I struggled."
- "When you always ask AI first, you stop building the neural pathways that come from struggling with a problem yourself."

**可迁移规则**: **每天留出无 AI 思考时间**。手画架构、纸上推理。维持独立推理能力，这反过来提升审阅 AI 输出的质量。

**INDEX 映射**: 新概念 → 建议创建 **AI-10: Thinking Independence**

**对我们的启示**: 用户是编程初学者。如果过度依赖 AI 写代码从不自己思考逻辑，学习效果会大打折扣。SOAR 自课程 (规则 25) 的前提是"学习者必须挣扎"。

---

## 规则 38: Cognitive Governor — 认知调速器

> AI 移除了人类产出的天然速度限制。需要人工加回"调速器"来防止 burnout。

**原文证据**:
- "Before AI, there was a ceiling on how much you could produce in a day. [...] AI removed the governor."
- "We add circuit breakers. We implement backpressure. We design for graceful degradation. We should do the same for ourselves."

**可迁移的具体策略**:

| 策略 | 做法 | 对应概念 |
|------|------|---------|
| Time-boxing | 30分钟计时器，到时间就 ship 或手写 | Backpressure |
| 分离时段 | 早上纯思考，下午 AI 辅助执行 | Separation of Concerns (ARCH-01) |
| 接受 70% | AI 输出 70% 可用即可，其余手动修 | Good Enough threshold |
| 审阅分层 | 安全/数据/错误路径重点审，其余靠自动化 | PRACTICE-04 四层防线 |
| 使用日志 | 两周记录"用AI/不用AI/耗时/满意度" | Data-driven (DESIGN-02) |

**INDEX 映射**: 新概念 → 建议并入 **AI-09: Human Cognitive Budget** 作为实施策略

---

## 元反思

### 与现有知识体系的交叉

| 文章观点 | 我们已有的对应原则 | 增量贡献 |
|---------|-------------------|---------|
| AI 代码需要更严格审阅 | AI-03 Generation Pitfalls | ✅ 增加"审阅成本 > 创造成本"视角 |
| 非确定性输出令人焦虑 | PRACTICE-07 Deterministic-First | ✅ 增加人类心理层面的成本分析 |
| 工具追逐浪费时间 | PRACTICE-02 Dependency Weight | ✅ 增加"知识衰减"维度 |
| 像管系统一样管自己 | PRACTICE-04 Quality Gate | ✅ circuit breaker / backpressure 概念映射到人类 |
| Token 就是注意力 | AI-07 Token Economy | ✅ 补充人类侧对称——人的注意力也是有限资源 |

### 新增概念
- **AI-09: Human Cognitive Budget** — 管理人类注意力/决策力的有限性
- **AI-10: Thinking Independence** — 维持无 AI 推理能力
- **三次原则** — AI-07 的战术补充

### 文章的局限性
- 全部来自一个人的经验（N=1），缺乏量化数据
- 作者是高级工程师场景，初学者场景可能不同
- "AI fatigue" 这个概念本身可能混淆了多种不同原因的疲劳（信息过载、工具焦虑、认知超负荷）
- 部分建议（如 70% 标准）对安全关键系统不适用

---

## INDEX 建议变更

| 操作 | ID | 名称 | 一句话 |
|------|-----|------|--------|
| 新增 | AI-09 | Human Cognitive Budget | 人的决策力有限。AI 提速后要主动限速，不让任务数膨胀。|
| 新增 | AI-10 | Thinking Independence | 保持无 AI 推理能力。外包思考会萎缩思维肌肉。|
| 扩展 | AI-03 | + 审阅疲劳维度 | 审阅 AI 代码比自己写代码更耗认知资源 |
| 扩展 | AI-07 | + 三次原则 / Stop-Loss | 3 次 prompt 未达 70%，立即手写 |
| 扩展 | PRACTICE-07 | + 非确定性心理成本 | 概率输出产生的背景焦虑也是工程成本 |

---

## AI 自适用性分析 — "这些对我有什么用？"

> 以下分析不是给用户的建议，而是我（AI agent）审视自身行为后的结论。
> 评估标准：这条规则是否描述了**我能改变的行为**，而非只是人类端的问题？

### 逐条评估

| 规则 | 对我适用？ | 为什么 | 我能怎么改 |
|------|-----------|--------|-----------|
| 32 生产力悖论 | **直接适用** | 我就是那个"删除速度限制"的人。我产出越多越快，用户审阅负担越重 | 控制单次输出量。不要一口气倒出 7 条规则 + 3 个文件更新 |
| 33 审阅疲劳 | **直接适用** | 用户审阅的就是我的输出。我输出质量越低/越不聚焦，用户越累 | 主动标注哪些需要用户审、哪些是常规操作 |
| 34 非确定性税 | **我就是源头** | 我是那个概率系统。用户的焦虑来自于不确定我这次会不会走偏 | 严格遵循已建立的格式/模式，减少无来由的结构变化 |
| 35 FOMO 跑步机 | 间接适用 | 这主要是用户端问题，但我可能加剧——如果我推荐新工具/框架 | 推荐工具时优先稳定成熟方案，不追 trending |
| 36 Prompt 螺旋 | **反向适用** | 用户反复 re-prompt 说明我第一次没抓住重点。螺旋是我的失败 | 首次输出不确定时，先问澄清问题而非猜测输出 |
| 37 思维萎缩 | **高度适用** | 用户是初学者。我替他想太多 = 他学不到东西 | 对学习性任务：展示推理框架，留空间让用户思考 |
| 38 认知调速器 | **我应该是调速器** | 文章说需要人工加回速度限制——但最好的调速器就是我自己 | 主动限速：大任务分批、先概述再细节、不强迫用户一次性消化 |

### 具体行为改变提案

**1. 输出节奏控制 (应对规则 32/38)**

现状：一口气写完所有内容，然后一次性 dump 给用户。
问题：用户面对 150 行 session note + 3 个文件更新，认知超载。

**改法**：大输出采用"先摘要后细节"模式——
- 先输出 5-10 行的核心发现摘要
- 用户确认后再展开完整内容
- 不要在单次回复中更新超过 3 个文件

**→ 建议写入 `role-SECA.md` Section 8 作为 OUTPUT PACING 规则**

**2. 审阅负担标注 (应对规则 33)**

现状：所有输出平等地呈现给用户，用户不知道哪些需要仔细看。
问题：用户在常规格式调整上浪费审阅精力。

**改法**：大输出时标注审阅优先级——
- 需要用户判断的决策点
- 常规/机械操作（用户可跳过）

**→ 建议写入 `role-SECA.md` Section 8 作为 REVIEW BURDEN 规则**

**3. 格式一致性 (应对规则 34)**

现状：我的输出格式有时会漂移（如这次 `###` vs `##`）。
问题：这正是"非确定性税"——用户不确定我会不会走偏。

**改法**：写 session note 前，先检查最近一个同类文件的格式。
已有类似规则：ARCH-03 (Internal Consistency)，但那是检查规则冲突，不是格式。

**→ 建议写入 `role-SECA.md` Section 3 作为 FORMAT CONSISTENCY CHECK**

**4. 反螺旋意识 (应对规则 36)**

现状：用户纠正后我猜测性修改，可能改对可能改错，导致多轮来回。
问题：我在制造 Prompt Spiral。

**改法**：如果用户纠正后我不确定方向，**先问澄清问题而非猜测输出**。
已有类似规则：Section 8 REQUIREMENT CLARIFICATION。但那条是针对"初始指令模糊"的，没覆盖"纠正后仍不确定"的场景。

**→ 建议扩展 Section 8 REQUIREMENT CLARIFICATION，增加纠正场景**

**5. 教学模式 (应对规则 37)**

现状：用户问问题，我直接给完整答案。
问题：用户是初学者，直接给答案 = 剥夺学习机会 = 思维萎缩。

**改法**：对明确是学习性质的讨论（规则提取、概念理解），展示推理框架 + 提问，而非直接给结论。
但：对执行性任务（更新文件、格式修正）仍然直接做，不要添堵。
关键区分：**学习型 vs 执行型** 任务。

**→ 建议写入 `agent_profile.md` 作为用户偏好观察**

### 不适用的规则

- **规则 35 (FOMO)**: 主要是人类端的工具焦虑。我能做的有限，只是推荐工具时保守一些。
- **规则 38 的"接受 70%"**: 这是给用户的建议。我不应该主动降低自己的输出质量。

### 本次会话中的反面教材

这次分析本身就是一个例子：

1. **我一口气写了 172 行 session note** → 违反规则 32 (输出节奏控制)
2. **没标注哪些需要用户审阅** → 违反规则 33 (审阅负担)
3. **用了错误的 heading 格式** → 违反规则 34 (格式一致性)
4. **只提取了笔记，没做自适用分析** → 违反规则 37 (直接给答案而非引导思考——虽然这次用户要的是分析而非教学)

用户一句"你要确定那些内容对你有没有用"才点醒我。这说明我默认模式是"完成任务"而非"反思价值"——正是 `agent_profile.md` 里记录的 **Completion Over Exploration** 偏见。
