# Session Note: 2026-02-13 AM (Part 2)

# 外部项目分析与前沿 AI 能力评估

> 来源 1: [quailyquaily/mistermorph](https://github.com/quailyquaily/mistermorph) (Go AI agent 框架)
> 来源 2: Google DeepMind Gemini Deep Think / Aletheia 公开信息, 2026-02
> 证据强度: `[开源代码 + 官方公告 + 学术论文]`

---

## MisterMorph 项目 — 可借鉴的设计模式

**项目概况**: Go 语言 AI agent 框架，带 Telegram bot 集成，9 个 feat doc 记录了系统设计。

### 借鉴点 1: Long-Term Memory 容量管理

**他们的做法**:
- 记忆分 long-term (`_index.md`, 高信号条目) 和 short-term (per-session, 自由写)
- Long-term 严格限制: **每 session 最多推 1 条**, 总量 ≤ 100 条 / 3000 字符
- 超容量时修剪 lowest-reuse 条目

**我们的行动**: 已写入 `role-SECA.md` Section 7 — INDEX MAINTENANCE 增加 Memory Capacity 规则。

**关联原则**: `AI-02` (Memory 质量 > 数量), 规则 15

### 借鉴点 2: Prompt Token 去重

system prompt 里手动写的 tool 描述与 API 自动传的 tool schema 重复 → 浪费 token。
解决: system prompt 只保留 tool 名称 + 一句话描述, 完整 schema 靠 API `tools` 字段传。

**我们的情况**: 依赖 IDE 实现, 暂时无法直接优化。记录备用。

**关联原则**: `AI-07` (Token 经济学)

### 借鉴点 3: Guard 模块的 Fail-Closed 设计

**核心**: 默认拒绝, 需要理由才放行。不是"默认允许, 出问题才拦"。

**我们已有的对应**: `role-SECA.md` Section 0 第 1 条 (修改核心文件先问许可)。

### 暂时不需要的功能

| 功能 | 原因 |
|------|------|
| Heartbeat (定期检查点) | 我们是交互式驱动, 非后台运行 |
| Workspace Persona (按工作区切人格) | 单用户单项目 |
| FSStore (統一文件存储层) | Go 内部基础设施, markdown 项目不需要 |
| Telegram Reactions | 不用 Telegram |

---

## Gemini Deep Think / Aletheia — 前沿 AI 能力评估

### 是什么

Aletheia 是基于 Gemini Deep Think 的**数学研究 agent**:
- 接收研究级数学问题 → 生成解法 → 内置 verifier 自检 → 发现错误自修正
- 能用 Google Search 查文献
- **能主动承认失败** — 不硬给错误答案

### 关键成就

| 时间 | 成就 | 证据强度 |
|------|------|----------|
| 2025 夏 | IMO 金牌水平 | `[官方公告, 已验证]` |
| 2026-01 | IMO-ProofBench Advanced 90%, PhD 级别持续进步 | `[论文, 已验证]` |
| 2026-02 | 解了 13 个 Erdős 问题, 其中 Erdős-1051 被审稿人评为"优雅且非平凡" | `[论文 + 同行评审]` |
| 2026-02 | Feng26 — 完全由 AI 独立完成的算术几何论文 | `[论文, 已验证]` |
| 2026-02 | LeeSeo26 — AI + 人类合作证明粒子交互系统边界 | `[论文, 已验证]` |

### 两个违反直觉的技术点

1. **更好的推理 + 更低的计算成本** — 找到了更高效的思考路径, 不是简单"想更久"
2. **主动承认失败** — verifier 检测到无法解决时, 报告失败而非编造答案

### 对规则 30 的影响

规则 30 当前定义: "AI 是概率插值器, 不能跳出训练分布"

**挑战**: Erdős 问题的解法被数学家评为"非平凡" → 不是简单模式匹配

**但**: 数学证明的推理步骤仍在训练数据覆盖的逻辑空间内。"新证明" ≠ "新数学概念"。

**建议修正**: "AI 是**组合创新器** — 能重组已有推理模式创造新组合, 但未证明能发明全新概念"

### AI Co-Scientist 系统

Google 同期发布的多 agent 科学助手:
- 自动综合文献 → 生成新假说 → 写实验代码验证

架构与我们的**规则 29 (Manager-Worker)** 一致: 不同 agent 分工, 强 agent 整合。

**核心理念**: AI 做知识检索 + 严格验证, 人做概念深度 + 创意方向。
这与 `_ai_evolution/` 的设计哲学完全一致 — AI 管机械的 (索引、脚本验证), 人管判断的 (规则取舍、方向决策)。

### Mathematical Research Autonomy Levels

DeepMind 提出的 AI 数学研究自主性分级框架:
- 用于透明地评估 AI 生成的数学结果
- 类比: 自动驾驶有 L1-L5, 数学研究也需要类似分级
- **对我们的意义**: 可以借鉴,对 AI 在本项目中的自主权建立类似分级 (见规则 19 四层防线)

---

## 本次修改清单

| 文件 | 改动 |
|------|------|
| `role-SECA.md` | Section 7 新增 Memory Capacity 规则 |
| `session_notes/RULES_CATALOG.md` | 新建, 38 条规则按类别索引 |
| `scripts/validate_sessions.py` | 支持 am 文件 + heading 格式检查 |
