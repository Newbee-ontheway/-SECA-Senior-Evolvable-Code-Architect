# Session Note: 2026-02-11 Late Night (Part 4)

# AI 工程：可靠性与资源优化

> 本笔记来自与 AI 的对话讨论，基于多方信息综合整理。
> 涉及的具体数据标注了证据强度。

---

## 规则 19：四层防线模型 — 约束 Agent 输出的通用框架

**INDEX 编号**: `PRACTICE-04` (Quality Gate) 的体系化扩展

**通俗解释**:
AI 的输出永远是概率性的，不可能通过 prompt 变成确定性的。
解决方案不是让 AI 变确定，而是用确定性的东西把它包住。

**四层防线**:

```
Layer 1: 缩小射程     ← 小任务 = 低不确定性
Layer 2: 结构化约束    ← 限制输出形状（格式/模板/规则）
Layer 3: 事后验证     ← 用确定性工具检查（编译器/测试）
Layer 4: 人类兜底     ← 关键决策由人做
```

| 层级 | 对应的已有规则 | 在我们系统中 |
|------|-------------|------------|
| Layer 1 | distributed_execution (≤3 文件/phase) | ✅ 已有 |
| Layer 2 | role-SECA.md, POST-GENERATION SELF-CHECK | ✅ 已有 |
| Layer 3 | 编译检查、lint | ⚠️ 部分覆盖 |
| Layer 4 | Permission Protocol, Pre-approval | ✅ 已有 |

**关键认知**: Layer 3（事后验证）必须用**确定性工具**（编译器、测试框架），
不能用另一个 AI — 那只是叠加不确定性，不是验证。

---

## 规则 20：Failure Mode Multiplication — 多 Agent 的可靠性陷阱

**INDEX 编号**: 新增 `ARCH-06`

**通俗解释**:
一条生产线有 10 个环节，每个环节 95% 成功率。
整条线的成功率 = 0.95^10 = 60%。环节越多越不可靠。

多 Agent 系统也一样：每加一个 Agent（不确定环节），总可靠性只会下降。

**多 Agent 架构对比**:

| 类型 | 通信方式 | 可靠性风险 |
|------|---------|-----------|
| 子代理 (Sub-agent) | 主→子→主 | 主 Agent 是单点故障 |
| 蜂群 (Swarm) | 去中心化 | 容错好但协调难 |
| 编排式 (Orchestrated) | 有协调器 | 最复杂，故障点最多 |
| **单 Agent + 工具** | 不需要 Agent 间通信 | **最简单最可靠** |

**结论**: 除非任务量大到一个 Agent 处理不过来，否则单 Agent + 确定性工具是最佳选择。

**判断标准**: "我需要多 Agent" 之前先问 — "一个 Agent + 更好的工具 能不能解决？"

---

## 规则 21：确定性优先 — 用最确定的方式做每件事

**INDEX 编号**: 新增 `PRACTICE-07`

**通俗解释**:
每件事都有多种做法，它们的确定性不同。优先选确定性高的。

**优先级排序**:

```
脚本 > 工具/命令 > MCP > Sub-agent > 多 Agent
确定性高 ←──────────────────────→ 确定性低
```

**判断方法**:

| 问题 | 答案 → 用什么 |
|------|-------------|
| 步骤固定、输入输出明确？ | → 脚本 |
| 步骤固定、需跟外部交互？ | → 工具/命令 |
| 需要调用外部 API？ | → MCP（连的是确定性服务时可靠） |
| 需要"看"和"判断"？ | → Sub-agent |
| 任务量大到一个做不完？ | → 多 Agent（最后手段） |

**自动化时机**: AI 探路（第一次做），搞清楚后写脚本（第二次起）。

---

## 规则 22：Token 是 AI 工程的核心资源 — 优化原则

**INDEX 编号**: `PRACTICE-AI-01` 的实践延伸

**通俗解释**:
传统软件工程优化 CPU、内存、带宽。
AI 工程优化 Token — 因为 Token 同时是钱和 AI 注意力。
省 Token = 省钱 + AI 回答质量更高。

**Token 消耗四分类**:

| 类型 | 能优化吗 | 优化策略 |
|------|---------|---------|
| 固定成本（规则/系统提示） | 压缩但不能省 | 规则写精简 |
| 累积成本（对话历史） | 拆 session | 大任务分多次，用 last_session.md 续传 |
| 按需成本（读文件/搜索） | 用最小工具 | 先 grep 再 view；先 outline 再全文 |
| 纯浪费 | 消除 | 重复读取、lint 噪音、过长解释 |

**六种已验证的优化策略**:

| 策略 | 传统工程叫法 | 在我们系统中 |
|------|-----------|------------|
| 分布式索引 | Lazy Loading | 不预读所有文件 |
| 原则 ID (ARCH-01) | 指针/引用 | ID 代替完整定义 |
| last_session.md | Checkpoint | Session 断点续传 |
| Startup 只读 3 文件 | 冷启动优化 | 最小启动集 |
| 确定性优先 | 计算下沉 | 脚本代替 AI |
| 精简规则 | 代码压缩 | 降低固定成本 |

**关键认知**: 减少轮次比缩短每轮更有效。
一次做准比试三次更省 — "先诊断再动手"也是 Token 优化。
