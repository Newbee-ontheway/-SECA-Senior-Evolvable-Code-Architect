# Session Note: 2026-02-11 Late Night (Part 2)

# AI 协作与决策透明度

> 本笔记涵盖两个跨领域经验：一个适用于所有技术决策，一个适用于 AI 协作。
> 原则定义见 [INDEX.md](./INDEX.md)。

---

## 规则 9：每个决策都要留下"为什么"的记录

**INDEX 编号**: `PRACTICE-03` (可追溯性)

**通俗解释**:
法庭判案需要判决书，写明"依据哪条法律、基于什么证据、推理过程是什么"。
技术决策也一样 -- 如果只有结论没有过程，将来出问题时没人知道当初为什么这样选。

**格式**:

```
[推理] 方案A兼容Python 3.14 → 方案B需要Rust编译 → 选A [依据: 已验证]
```

三个证据强度标签：
- **已验证** -- 跑过了、测过了、亲眼看到输出
- **有依据** -- 文档/先例支持，但这次没亲自验证
- **推测** -- 没有具体依据，明确标出来

**什么时候用**:
- 有两个以上可行方案时 → 用
- 只有一条路时 → 不用（浪费时间）
- 判断标准：**有选择才需要推理链**

**你以后做任何项目时**:
当你（或 AI）做了一个技术决定，问自己：
"如果三个月后回来看这个决定，我能理解当时为什么这样选吗？"
如果不能 → 补一条推理链。

---

## 规则 10：理解 AI 的"工作台"大小

**INDEX 编号**: `PRACTICE-AI-01` (上下文窗口管理)

**为什么小白需要知道这个**:
AI 不是"知道一切"的神。它有一个隐形的限制 -- **上下文窗口**。
不理解这个限制，你会遇到"AI 突然变蠢"的问题，但不知道为什么。

**核心概念**:

```
上下文窗口 = 书桌大小

你和 AI 说的每句话 = 桌上放的一张纸
AI 读的每个文件 = 桌上放的一叠文件
工具输出 (lint 警告等) = 桌上放的报告

桌子放满了 → 新纸只能盖在旧纸上 → 旧纸看不见了
= AI "忘记"了前面的对话
```

**你怎么判断"桌子快满了"**:

| 信号 | 含义 |
|------|------|
| AI 忘了前面说过的事 | 旧内容被截断 |
| AI 回复突然变短 | 剩余空间不够生成完整回答 |
| 系统提示 "checkpoint" | 已触发截断机制 |
| 需要说 "Continue" | 可能是上下文压力 |

**解决方案**:

1. **大任务拆成多次对话** -- 每次 1-2 个子任务
2. **用 `last_session.md` 存档** -- AI 下次能无损恢复状态
3. **避免在一轮里做太多** -- 读 5+ 大文件 = 快速填满

**关键认知**:
AI 的训练知识 (长期记忆) 和上下文窗口 (工作记忆) 是分开的。
训练知识不会被对话消耗，但你的项目细节只存在于上下文窗口里。
所以 AI "知道什么是 Python" (训练知识) 但可能 "忘了你的文件叫什么" (上下文被截断)。
