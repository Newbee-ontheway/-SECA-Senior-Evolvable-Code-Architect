# Session Note: 2026-02-12 Afternoon (Part 2)

# SOAR: 让 AI 自己教自己突破推理瓶颈

> 来源: MIT + Meta FAIR + NYU, 2026-01-27
> 论文: "Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability"
> 作者: Shobhita Sundaram et al.
> 证据强度: `[同行评审论文, 实验验证]`

---

## 规则 25：学不会不一定是笨 — 可能是教法的问题

**核心问题**: AI 用强化学习提升推理时遇到死循环：题太难 → 成功率≈0 → RL 没有梯度信号 → 停止进步。

**SOAR 的解法**: 用同一个模型拆成 Teacher 和 Student：
- Teacher 出合成题，Student 练习
- Teacher 的奖励 = Student 在**真题**上进步了多少
- 合成题不需要正确答案 — 结构比内容重要

**关键洞察**:
1. "推理极限"很多不是智力极限，而是**课程设计极限**
2. Teacher 学会出"刚好够难"的题 — 维果茨基的最近发展区 (ZPD)
3. 不需要新架构、额外人类数据、更大模型 — 只需改变奖励目标
4. 奖励"学习进步"而非"正确答案"

**实验结果**: 在数学基准最难子集（初始 0/128 成功率），传统 RL 完全停滞，SOAR 持续上升。

**与已有原则的联系**:
- `Errors are Data` — 错误是学习信号，SOAR 证明了即使全错也能产生学习信号
- `DESIGN-04` 正交分解 — 把难任务拆成可训练的中间步骤
- `PRACTICE-04` Quality Gate — 渐进式检查 ≈ 渐进式难度

**对教材项目的启发**: 好教材的本质是好的 curriculum design。练习题的**结构**比答案更重要，难度应该在学生的 ZPD 边界上。→ 写入 Spark-002

---

## 元反思：推理链 vs 行动优先

用户指出我最近跳过推理链直接行动。原因分析：
- 写文件的操作越来越熟练，我开始"省略推理过程"
- 但用户的核心需求是**学习**，推理过程本身有教学价值
- 修正：先展示思考链 → 用户确认 → 再写入
