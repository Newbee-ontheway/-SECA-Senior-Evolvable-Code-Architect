# Research: BM25 æœ¬åœ°æœç´¢æ–¹æ¡ˆ

**Date**: 2026-02-13
**Question**: ç”¨ä»€ä¹ˆæ–¹æ¡ˆå®ç° `_ai_evolution/` æœ¬åœ° markdown æ–‡ä»¶çš„ BM25 æœç´¢ï¼Ÿ

## ç ”ç©¶ç»“è®º

**æ¨èæ–¹æ¡ˆ**: `rank-bm25`ï¼ˆæœ€ç®€å•ï¼‰ æˆ– `BM25S`ï¼ˆæ›´å¿«ï¼Œæ”¯æŒç´¢å¼•æŒä¹…åŒ–ï¼‰

**æ¶æ„**: AI æ„å›¾æ¾„æ¸…ï¼ˆè¯­ä¹‰â†’å…³é”®è¯ï¼‰+ BM25 å…³é”®è¯æœç´¢ = è½»é‡æ··åˆæ–¹æ¡ˆ

## å€™é€‰æ–¹æ¡ˆå¯¹æ¯”

| å·¥å…· | ä¾èµ– | ä»£ç é‡ | ç´¢å¼•æŒä¹…åŒ– | é€‚åˆè§„æ¨¡ | åˆ¤æ–­ |
|------|------|--------|-----------|---------|------|
| **rank-bm25** | numpy | ~10 è¡Œ | âŒ æ¯æ¬¡å†…å­˜é‡å»º | <500 æ–‡ä»¶ | âœ… æœ€ç®€å•ï¼Œå¤Ÿç”¨ |
| **BM25S** | scipy, numpy | ~15 è¡Œ | âœ… save/load | <100ä¸‡ | âœ… æ¨èï¼Œæœ‰ç´¢å¼•ç¼“å­˜ |
| **Whoosh** | çº¯ Python | ~30 è¡Œ | âœ… æ–‡ä»¶ç´¢å¼• | <å‡ åƒ | ğŸ”§ åŠŸèƒ½å…¨ä½†åé‡ |
| **dotMD** | è¯­ä¹‰æ¨¡å‹+BM25+KG | ç‹¬ç«‹å·¥å…· | âœ… | ä»»æ„ | âŒ å¤ªé‡ï¼Œå«å‘é‡æ£€ç´¢ |
| **tantivy-py** | Rust ç¼–è¯‘å™¨ | ~20 è¡Œ | âœ… | ç™¾ä¸‡çº§ | âŒ ç¯å¢ƒä¾èµ–å¤ªé‡ |

## rank-bm25 æœ€å°ç¤ºä¾‹

```python
from rank_bm25 import BM25Okapi
import os, re

def load_markdown_files(directory):
    docs, paths = [], []
    for root, _, files in os.walk(directory):
        for f in files:
            if f.endswith('.md'):
                path = os.path.join(root, f)
                with open(path, 'r', encoding='utf-8') as fp:
                    docs.append(fp.read())
                paths.append(path)
    return docs, paths

def tokenize(text):
    """ç®€å•åˆ†è¯ï¼šè‹±æ–‡æŒ‰ç©ºæ ¼ï¼Œä¸­æ–‡æŒ‰å­—"""
    text = text.lower()
    text = re.sub(r'[#*\-_`\[\](){}|>]', ' ', text)  # å» markdown æ ‡è®°
    tokens = text.split()
    return tokens

# æ„å»ºç´¢å¼•
docs, paths = load_markdown_files('_ai_evolution/')
tokenized = [tokenize(doc) for doc in docs]
bm25 = BM25Okapi(tokenized)

# æœç´¢
query = "session end workflow cleanup"
query_tokens = tokenize(query)
scores = bm25.get_scores(query_tokens)

# å– top 5
top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:5]
for i in top_indices:
    if scores[i] > 0:
        print(f"  {scores[i]:.2f}  {paths[i]}")
```

## BM25S ç‰ˆæœ¬ï¼ˆæ”¯æŒç´¢å¼•æŒä¹…åŒ–ï¼‰

```python
import bm25s

# æ„å»ºç´¢å¼•ï¼ˆé¦–æ¬¡ï¼‰
corpus = [open(p, encoding='utf-8').read() for p in paths]
corpus_tokens = bm25s.tokenize(corpus, stopwords="en")
retriever = bm25s.BM25()
retriever.index(corpus_tokens)
retriever.save("_ai_evolution/.bm25_index", corpus=corpus)

# åŠ è½½ç´¢å¼•ï¼ˆåç»­ï¼‰
retriever = bm25s.BM25.load("_ai_evolution/.bm25_index", load_corpus=True)

# æœç´¢
query_tokens = bm25s.tokenize("session end workflow", stopwords="en")
results, scores = retriever.retrieve(query_tokens, k=5)
```

## ä½ çš„æ¶æ„ vs å‘é‡æ£€ç´¢

```
ä½ é€‰æ‹©çš„æ–¹æ¡ˆï¼ˆBM25 + AI æ„å›¾æ¾„æ¸…ï¼‰:
  ç”¨æˆ·: "æˆ‘ä¹‹å‰å†™è¿‡å…³äºæ€ä¹ˆç»“æŸä¼šè¯çš„"
  AI:   â†’ å…³é”®è¯: "session", "end", "cleanup", "ä¼šè¯", "ç»“æŸ"
  BM25: â†’ workflows/session_end.md (score: 12.4)
         â†’ last_session.md (score: 5.1)

å‘é‡æ£€ç´¢æ–¹æ¡ˆï¼ˆéœ€è¦ 100MB æ¨¡å‹ï¼‰:
  ç”¨æˆ·: "æˆ‘ä¹‹å‰å†™è¿‡å…³äºæ€ä¹ˆç»“æŸä¼šè¯çš„"
  æ¨¡å‹: â†’ å‘é‡ [0.23, -0.11, 0.87, ...]
  FAISS: â†’ workflows/session_end.md (cosine: 0.91)
```

**ç»“è®º**: åœ¨æ–‡ä»¶é‡ <100 çš„æƒ…å†µä¸‹ï¼ŒBM25 + AI æ„å›¾æ¾„æ¸…
çš„æ•ˆæœä¸ä¼šæ¯”å‘é‡æ£€ç´¢å·®å¤šå°‘ï¼Œä½†é›¶é¢å¤–ä¾èµ–ã€é›¶é¢å¤–å­˜å‚¨ã€‚
ç­‰æ–‡ä»¶é‡è¶…è¿‡ 200+ ä¸”é¢‘ç¹å‡ºç°"æ‰¾ä¸åˆ°"çš„ç—›ç‚¹æ—¶ï¼Œå†è€ƒè™‘å‘é‡æ£€ç´¢ã€‚

## ä¸‹ä¸€æ­¥

å¦‚æœå†³å®šå®æ–½ï¼š
1. `pip install rank-bm25`ï¼ˆæˆ– `bm25s`ï¼‰
2. å†™ä¸€ä¸ª `_ai_evolution/scripts/local_search.py`
3. é›†æˆåˆ° Skill #0 çš„ Local Recall åˆ†æ”¯
4. æ³¨å†Œåˆ° `project_context.md` tools è¡¨

## Sources

- [BM25S GitHub](https://github.com/xhluca/bm25s) â€” 500x faster than rank-bm25, scipy-based
- [rank-bm25 PyPI](https://pypi.org/project/rank-bm25/) â€” simplest BM25, 2-line search engine
- [Whoosh ReadTheDocs](https://whoosh.readthedocs.io/) â€” pure Python full-text search
- [dotMD Reddit](https://reddit.com/r/LocalLLaMA) â€” hybrid search for markdown (BM25 + vectors + KG)
- Forbes, ThoughtWorks, MadDevs â€” Build vs Buy decision frameworks
